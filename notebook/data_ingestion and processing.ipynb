{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8585edec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Logged in as: Faya\n"
     ]
    }
   ],
   "source": [
    "from telethon import TelegramClient\n",
    "import asyncio\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # loads variables from .env\n",
    "\n",
    "api_id = os.getenv(\"API_ID\")\n",
    "api_hash = os.getenv(\"API_HASH\")\n",
    "session_name = 'ethio_session'\n",
    "phone = '+251954504193'  # remove spaces\n",
    "\n",
    "\n",
    "# === List of e-commerce Telegram channels ===\n",
    "channels = [\n",
    "    'Leyueqa',\n",
    "    'nevacomputer',\n",
    "    'ZemenExpress',\n",
    "    'meneshayeofficial',\n",
    "    'ethio_brand_collection'\n",
    "]\n",
    "\n",
    "# === Directory setup ===\n",
    "os.makedirs('data/raw', exist_ok=True)\n",
    "os.makedirs('data/clean', exist_ok=True)\n",
    "\n",
    "# === Amharic text preprocessing function ===\n",
    "def preprocess_amharic(text):\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)  # Remove URLs\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()  # Normalize whitespace\n",
    "    text = text.replace(\"\\u1369\", \"1\")  # Ethiopic digit example\n",
    "    return text\n",
    "\n",
    "# === Fetch messages function ===\n",
    "async def fetch_messages(channel):\n",
    "    channel_entity = await client.get_entity(channel)\n",
    "    messages = []\n",
    "    async for message in client.iter_messages(channel_entity, limit=100):\n",
    "        all_records = []\n",
    "        for channel in channels:\n",
    "            print(f\"Fetching from: {channel}\")\n",
    "            try:\n",
    "                entity = await client.get_entity(channel)\n",
    "                async for msg in client.iter_messages(entity, limit=100):\n",
    "                    record = {\n",
    "                        'channel': channel,\n",
    "                        'message_id': msg.id,\n",
    "                        'date': msg.date.isoformat(),\n",
    "                        'sender_id': msg.sender_id,\n",
    "                        'raw_text': msg.message,\n",
    "                        'clean_text': preprocess_amharic(msg.message),\n",
    "                        'media': None\n",
    "                    }\n",
    "                    # Download media if available\n",
    "                    if msg.media:\n",
    "                        media_path = f\"data/raw/{channel}_{msg.id}\"\n",
    "                        await msg.download_media(media_path)\n",
    "                        record['media'] = media_path\n",
    "                    all_records.append(record)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed for {channel}: {e}\")\n",
    "\n",
    "        # Save to CSV\n",
    "        df = pd.DataFrame(all_records)\n",
    "        df.to_csv(\"data/clean/preprocessed_messages.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "        print(\"✅ Data ingestion and preprocessing complete.\")\n",
    "client = TelegramClient(session_name, api_id, api_hash)\n",
    "# Define main function\n",
    "async def main():\n",
    "    await client.start(phone=phone)\n",
    "    me = await client.get_me()\n",
    "    print(f\"✅ Logged in as: {me.first_name}\")\n",
    "    await client.disconnect()\n",
    "# === Run it ===\n",
    "if __name__ == \"__main__\":\n",
    "    await main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fca4a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching from: Leyueqa\n",
      "Fetching from: nevacomputer\n",
      "Fetching from: ZemenExpress\n",
      "Fetching from: meneshayeofficial\n",
      "Fetching from: ethio_brand_collection\n",
      "Saved CSV and JSON with text, phones, and prices.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def extract_phone_numbers(text):\n",
    "    if not text:\n",
    "        return []\n",
    "    pattern = r'\\+?\\d[\\d\\s\\-]{7,}\\d'\n",
    "    return re.findall(pattern, text)\n",
    "\n",
    "def extract_prices(text):\n",
    "    if not text:\n",
    "        return []\n",
    "    pattern = r'\\b\\d{1,6}(\\.\\d{1,2})?\\s?(birr|etb|₨)?\\b'\n",
    "    # Returns list of tuples, take first element of each\n",
    "    matches = re.findall(pattern, text.lower())\n",
    "    return [m[0] for m in matches]\n",
    "\n",
    "async def fetch_messages(channel):\n",
    "    print(f\"Fetching from: {channel}\")\n",
    "    all_records = []\n",
    "    try:\n",
    "        entity = await client.get_entity(channel)\n",
    "        async for msg in client.iter_messages(entity, limit=100):\n",
    "            raw_text = msg.message or \"\"\n",
    "            phones = extract_phone_numbers(raw_text)\n",
    "            prices = extract_prices(raw_text)\n",
    "            record = {\n",
    "                'channel': channel,\n",
    "                'message_id': msg.id,\n",
    "                'date': msg.date.isoformat(),\n",
    "                'text': raw_text,\n",
    "                'phone_numbers': phones,\n",
    "                'prices': prices,\n",
    "            }\n",
    "            all_records.append(record)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed for {channel}: {e}\")\n",
    "    return all_records\n",
    "\n",
    "async def main():\n",
    "    await client.start(phone=phone)\n",
    "    all_data = []\n",
    "    for channel in channels:\n",
    "        records = await fetch_messages(channel)\n",
    "        all_data.extend(records)\n",
    "\n",
    "    # Save as CSV\n",
    "    df = pd.DataFrame(all_data)\n",
    "    df.to_csv(\"data/clean/messages_with_contacts_and_prices.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "    # Save as JSON\n",
    "    with open(\"data/clean/messages_with_contacts_and_prices.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(all_data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "    print(\"Saved CSV and JSON with text, phones, and prices.\")\n",
    "    await client.disconnect()\n",
    "\n",
    "await main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46680fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scheduler started. Waiting for scheduled time...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 76\u001b[39m\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m     75\u001b[39m     schedule.run_pending()\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m     time.sleep(\u001b[32m1\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from telethon import TelegramClient, events\n",
    "import os\n",
    "import asyncio\n",
    "import schedule\n",
    "import time\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # loads variables from .env\n",
    "\n",
    "API_ID = os.getenv(\"API_ID\")\n",
    "API_HASH = os.getenv(\"API_HASH\")\n",
    "\n",
    "session_name = 'ethio_session'\n",
    "phone = '+251954504193'\n",
    "\n",
    "channels = [\n",
    "    'Leyueqa',\n",
    "    'nevacomputer',\n",
    "    'ZemenExpress',\n",
    "    'meneshayeofficial',\n",
    "    'ethio_brand_collection'\n",
    "]\n",
    "\n",
    "os.makedirs('data/real_time/raw', exist_ok=True)\n",
    "os.makedirs('data/clean', exist_ok=True)\n",
    "\n",
    "client = TelegramClient(session_name, api_id, api_hash)\n",
    "\n",
    "def preprocess_text(text):\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    return text.strip()\n",
    "\n",
    "@client.on(events.NewMessage(chats=channels))\n",
    "async def handler(event):\n",
    "    msg = event.message\n",
    "    data = {\n",
    "        'channel': event.chat.username if event.chat else None,\n",
    "        'message_id': msg.id,\n",
    "        'date': msg.date.isoformat(),\n",
    "        'sender_id': msg.sender_id,\n",
    "        'text': preprocess_text(msg.message),\n",
    "        'media': None\n",
    "    }\n",
    "\n",
    "    if msg.media:\n",
    "        media_path = f\"data/real_time/raw/{data['channel']}_{msg.id}\"\n",
    "        await msg.download_media(media_path)\n",
    "        data['media'] = media_path\n",
    "\n",
    "    df = pd.DataFrame([data])\n",
    "    csv_path = \"data/clean/messages_with_contacts_and_prices.csv\"\n",
    "    if not os.path.exists(csv_path):\n",
    "        df.to_csv(csv_path, index=False, encoding=\"utf-8-sig\")\n",
    "    else:\n",
    "        df.to_csv(csv_path, mode='a', header=False, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"New message collected from {data['channel']}: {data['text'][:30]}...\")\n",
    "\n",
    "async def main():\n",
    "    await client.start(phone=phone)\n",
    "    print(\"Listening for new messages...\")\n",
    "    await client.run_until_disconnected()\n",
    "\n",
    "def run_listener():\n",
    "    print(\"Starting listener at scheduled time...\")\n",
    "    asyncio.run(main())  # Properly run async main in sync function\n",
    "\n",
    "# Schedule to run every day at 08:00 AM\n",
    "schedule.every().day.at(\"08:00\").do(run_listener)\n",
    "\n",
    "print(\"Scheduler started. Waiting for scheduled time...\")\n",
    "\n",
    "while True:\n",
    "    schedule.run_pending()\n",
    "    time.sleep(1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7022f6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Load CSV\n",
    "df = pd.read_csv(\"data/clean/messages_with_contacts_and_prices.csv\", encoding=\"utf-8-sig\")\n",
    "\n",
    "def preprocess_amharic(text):\n",
    "    if not isinstance(text, str):\n",
    "        return []\n",
    "    # Remove URLs\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "    # Remove punctuation (you can customize for Amharic punctuation)\n",
    "    text = re.sub(r\"[!\\\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~]\", \" \", text)\n",
    "    # Normalize whitespace\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    # Lowercase (Amharic script doesn’t have case, but safe for mixed text)\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Optional: Normalize Amharic-specific chars (example: replace አ and ኣ to one form)\n",
    "    # text = text.replace('አ', 'ኣ')  # example replacement, adjust as needed\n",
    "\n",
    "    # Tokenize - using nltk (download punkt tokenizer before running)\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "# Apply preprocessing and create new column\n",
    "df['tokens'] = df['text'].apply(preprocess_amharic)\n",
    "\n",
    "# Example: Save back to CSV or use df['tokens'] for further analysis\n",
    "df.to_csv(\"data/clean/messages_preprocessed.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "008cb68f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Record 1 tokens: ['🔥🔥saachi', 'አንጀት', 'አርስ', 'ስቶቭ', 'ባለ', '2', 'ተች', 'ስቶቭ', '🔄an', 'environmentally', 'friendly', 'and', 'safe', 'plate', 'based', 'on', 'a', 'light', 'wave', '💯light', 'wave', 'technology', '💯safe', 'and', 'high', 'quality', '⛔️does', 'not', 'emit', 'smoke', 'and', 'flame', 'suitable', 'for', 'this', 'product', 'cooking', '🙂can', 'be', 'roasted', 'and', 'steamed', 'this', 'appliance', 'can', 'perform', 'a', 'variety', 'of', 'functions', 'including', 'a', 'multi', 'function', 'plate', 'has', 'a', 'heating', 'function', '🟢ግዜዎን', 'እና', 'ጉልበትዎን', 'የሚቆጥብ', 'ፈጣን', 'ስቶቭ', '🟢ባለ', '2', 'price', '9500', 'delivery', 'free', 'ክፍያዎን', 'ዕቃዉ', 'እጅዎ', 'ሲደርስ', 'በሞባይል', 'ባንኪንግ', 'መፈፀም', 'ይችላሉበተጨማሪ', 'ሁለት', 'ዕቃዎችን', 'ከ', '1000', 'ብር', 'በላይ', 'የሚተመኑ', '2', 'ዕቃዎችን', 'አንዴ', 'ሲገዙ', 'ስጦታ', 'እንልክለዎታለን', '0933334444', 'lemazez', 'z', '0944109295', 'lemaze', 'z', '0946242424', 'le', 'mazez']\n",
      "Record 2 tokens: ['👉👉👉super', 'stretch', 'silicon', 'lids', '6', 'pack', '🔰የዕቃ', 'መሸፈኛ', 'ሲሊከን', 'ፕላስቲኮች', 'በተደጋጋሚ', 'የምንጠቀምባቸዉ', 'በተለያዩ', 'ሳይዞች', 'የቀረቡ', 'የሚለጠጥ', 'የማይቀደድ', 'kitchen', 'home', 'silicone', 'stretch', 'lids', 'set', 'of', '6', 'silicone', 'food', 'saver', 'covers', '🔰', 'superior', 'quality', '🔰', 'lids', 'that', 'fit', '🔰', 'reusable', '🔰', 'temperature', 'resistant', '🔰', 'food', 'safe', 'ዋጋ👉', '450ብር', 'በተጨማሪ', 'ከ', '1000', 'ብር', 'በላይ', 'የሆኑ', 'ሁለት', 'ዕቃዎች', 'በአንድዲሊቨሪ', 'ግዜ', 'ሲያዙ', 'ስጦታ', 'እንልክለዎታለን', '🎁', 't', 'me', 'leyueqa', '👈ቻናላችንን', 'ለጓደኛዎ', 'ሸር', 'ማድረግዎን', 'አይርሱ', '0933334444', 'lemazez', 'z', '0944109295', 'lemaze', 'z', '0946242424', 'le', 'mazez']\n",
      "Record 3 tokens: ['🔝🔝🔝saachi', '3', 'in', '1', 'original', 'የጁስ', 'የቡና', 'የቅመም', '➕1', '6', 'litre', 'high', 'capacity', 'plastic', 'jar', '➕2', 'speed', 'control', 'with', 'pulse', '➕full', 'safety', 'switch', '⚡️powerful', 'motor', '⭐️ultra', 'sharp', 'blade', '✅rotary', 'switch', 'for', 'easy', 'operate', '🔻plastic', 'lined', 'grinding', 'mill', '💵ዋጋ', '2900', 'ከነፃ', 'ዲሊቨሪ', 'ጋር', '💵', '🔖አድራሻ', '🥇ቁጥር', '1', 'ልደታ', 'ወደ', 'ባልቻ', 'ሆስፒታል', 'ገባ', 'ብሎ', 'አህመድ', 'ህንፃ', 'ላይ', '1ኛፎቅ', '114b', 'ባሉበት', 'ያለተጨማሪ', 'ክፍያ', 'ማዘዝ', 'ይችላሉ', '0933334444', 'lemazez', 'z', '0946242424', 'le', 'mazez', '0944109295', 'lemaze', 'z']\n",
      "Record 4 tokens: []\n",
      "Record 5 tokens: []\n",
      "Record 6 tokens: []\n",
      "Record 7 tokens: []\n",
      "Record 8 tokens: ['🔝🔝🔝🔝bamboo', 'trey', '3pc', '✅', 'price✅', '3300', 'ከነፃ', 'ዲሊቨሪ', 'ጋር', '0933334444', 'lemazez', 'z', '0946242424', 'le', 'mazez', '0944109295', 'lemaze', 'z', 'ክፍያዎን', 'በሞባይል', 'ባንኪንግ', 'መፈፀምም', 'ይችላሉ', 'በተጨማሪ', 'ከ', '1000', 'ብር', 'በላይ', 'የሆኑ', 'ሁለት', 'ዕቃዎች', 'ሲገዙ', 'ስጦታ', 'እንልክለዎታለን', '🎁', 't', 'me', 'leyueqa', '👈ቻናላችንን', 'ለጓደኛዎ', 'ሸር', 'ማድረግዎን', 'አይርሱ']\n",
      "Record 9 tokens: ['🛡🛡🛡ዉሃ', 'ስርገትን', 'ወደ', 'ፍራሽ', 'ዉስጥ', 'እንዳይገባ', 'እና', 'አላስፈላጊ', 'ሽታን', 'እንዲሁም', 'ድካምን', 'የሚከላከል', 'አንሶላ', 'mattress', 'protector', 'polyester', 'microfiber', '✔️ለ', '1', '50', '✔️ለ', '1', '80', 'ከነፃ', 'ዲሊቨሪ', 'ጋር', '3500', 'ብር', '💵💵', '📌📌📌አድራሻ', '⭕️ቁጥር', '1', 'ልደታ', 'ወደ', 'ባልቻ', 'ሆስፒታል', 'ገባ', 'ብሎ', 'አህመድ', 'ህንፃ', 'ላይ', '1ኛፎቅ', '114b', 'ባሉበት', 'ያለተጨማሪ', 'ክፍያ', 'ማዘዝ', 'ይችላሉ', '0933334444', 'lemazez', 'z', '0946242424', 'le', 'mazez', '0944109295', 'lemaze', 'z']\n",
      "Record 10 tokens: ['💙💙💙💙💙💙💙', 'kitchen', 'oil', 'proof', 'stickers', 'ለኪችንዎ', 'ግርማሞገስ', 'የሚያላብስ', 'ኪችንዎን', 'ፅድት', 'የሚያደርግ', '⭐️ለመሳቢያ', '፣', 'ለካቢኔ', '፣', 'ለኩሽና', '፣', 'ለስላሳ', 'የእንጨት', 'ገጽና', 'ግድግዳ', 'ላይ', 'የሚለጠፍ', 'በራሱ', 'የሚጣበቅ', 'ውሃ', 'የማያሳልፍ', 'waterproof', 'የሆነ', '⭐️ስፋት', '60cm×5meter', 'ሜትር', 'ዋጋ', '1200', 'ብር', 'ሲያዙ', 'ነፃ', 'ዲሊቨሪ', '⭐️ሙቀትንእና', 'እርጥበትን', 'የሚቋቋም', 'ለማፅዳት', 'ቀላል', '0933334444', 'lemazez', 'z', '0944109295', 'lemaze', 'z', '0946242424', 'le', 'mazez', '🔺አድራሻ', '⭕️ቁጥር', '1', 'ልደታ', 'ወደ', 'ባልቻ', 'ሆስፒታል', 'ገባ', 'ብሎ', 'አህመድ', 'ህንፃ', 'ላይ', '1ኛፎቅ', '114b']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the preprocessed CSV with the tokens column\n",
    "df = pd.read_csv(\"data/clean/messages_preprocessed.csv\", encoding=\"utf-8-sig\")\n",
    "\n",
    "# The 'tokens' column contains lists stored as strings, so convert them back to lists\n",
    "import ast\n",
    "\n",
    "df['tokens'] = df['tokens'].apply(ast.literal_eval)\n",
    "\n",
    "# Now print the first 10 rows of tokens\n",
    "for i, tokens in enumerate(df['tokens'].head(10)):\n",
    "    print(f\"Record {i+1} tokens:\", tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1043bdcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel</th>\n",
       "      <th>message_id</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>phone_numbers</th>\n",
       "      <th>prices</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>nevacomputer</td>\n",
       "      <td>8733</td>\n",
       "      <td>2025-03-20T12:43:37+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>nevacomputer</td>\n",
       "      <td>8774</td>\n",
       "      <td>2025-06-11T13:56:52+00:00</td>\n",
       "      <td>LENOVO X1 YOGA\\nProcessor: 11th‑Gen Intel Core...</td>\n",
       "      <td>['+251912759900', '+251920153333']</td>\n",
       "      <td>['', '', '.8', '.7', '', '', '', '', '', '', '...</td>\n",
       "      <td>[lenovo, x1, yoga, processor, 11th‑gen, intel,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          channel  message_id                       date  \\\n",
       "139  nevacomputer        8733  2025-03-20T12:43:37+00:00   \n",
       "101  nevacomputer        8774  2025-06-11T13:56:52+00:00   \n",
       "\n",
       "                                                  text  \\\n",
       "139                                                NaN   \n",
       "101  LENOVO X1 YOGA\\nProcessor: 11th‑Gen Intel Core...   \n",
       "\n",
       "                          phone_numbers  \\\n",
       "139                                  []   \n",
       "101  ['+251912759900', '+251920153333']   \n",
       "\n",
       "                                                prices  \\\n",
       "139                                                 []   \n",
       "101  ['', '', '.8', '.7', '', '', '', '', '', '', '...   \n",
       "\n",
       "                                                tokens  \n",
       "139                                                 []  \n",
       "101  [lenovo, x1, yoga, processor, 11th‑gen, intel,...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(2)  # Random 10 rows (good for getting a feel of the dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83c006f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔎 Missing/Nan values in 'tokens' column: 0\n",
      "Empty token lists: 190\n"
     ]
    }
   ],
   "source": [
    "missing_tokens_count = df['tokens'].isna().sum()\n",
    "print(f\"🔎 Missing/Nan values in 'tokens' column: {missing_tokens_count}\")\n",
    "empty_tokens_count = df['tokens'].apply(lambda x: isinstance(x, list) and len(x) == 0).sum()\n",
    "print(f\"Empty token lists: {empty_tokens_count}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61bae447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleaned DataFrame: 310 rows remaining\n"
     ]
    }
   ],
   "source": [
    "df = df[df['tokens'].apply(lambda x: len(x) > 0 if isinstance(x, list) else False)].reset_index(drop=True)\n",
    "df.to_csv(\"data/clean/structured_telegram_messages_cleaned.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"✅ Cleaned DataFrame: {len(df)} rows remaining\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e32645a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Structured data saved.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import ast\n",
    "\n",
    "# Load raw message CSV (you can also load from JSON and convert)\n",
    "df = pd.read_csv(\"data/clean//structured_telegram_messages_cleaned.csv\", encoding=\"utf-8-sig\")\n",
    "\n",
    "# If tokens are saved as strings, convert to actual list\n",
    "if df['tokens'].dtype == object and isinstance(df['tokens'].iloc[0], str):\n",
    "    df['tokens'] = df['tokens'].apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "# Clean the text content\n",
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)  # Remove URLs\n",
    "    text = re.sub(r\"[\\\"#$%&'()*+/<=>@[\\]^_`{|}~፣።]\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "df['clean_text'] = df['text'].apply(clean_text)\n",
    "\n",
    "# Extract tokens (simple whitespace-based for Amharic)\n",
    "df['tokens'] = df['clean_text'].apply(lambda x: x.split())\n",
    "\n",
    "# Extract flag if the message contains phone number or price\n",
    "def contains_phone(text):\n",
    "    return bool(re.search(r\"\\b09\\d{8}\\b\", text))\n",
    "\n",
    "def contains_price(text):\n",
    "    return bool(re.search(r\"(?:birr|ብር|\\b\\d{2,7}\\b)\", text, re.IGNORECASE))\n",
    "\n",
    "df['contains_phone'] = df['text'].apply(contains_phone)\n",
    "df['contains_price'] = df['text'].apply(contains_price)\n",
    "\n",
    "# Optional: Create a 'content' column for easier reference\n",
    "df['content'] = df['clean_text']\n",
    "\n",
    "# Reorder and structure columns\n",
    "metadata_cols = ['channel', 'message_id', 'date']\n",
    "content_cols = ['text', 'clean_text', 'tokens', 'phone_numbers', 'prices']\n",
    "\n",
    "df_structured = pd.DataFrame()\n",
    "df_structured[metadata_cols] = df[metadata_cols]\n",
    "df_structured['raw_text'] = df['text']\n",
    "df_structured['clean_text'] = df['clean_text']\n",
    "df_structured['tokens'] = df['tokens']\n",
    "df_structured['contains_phone'] = df['contains_phone']\n",
    "df_structured['contains_price'] = df['contains_price']\n",
    "\n",
    "# Save to CSV\n",
    "df_structured.to_csv(\"data/clean/structured_telegram_messages.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "print(\"✅ Structured data saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b0c974b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel</th>\n",
       "      <th>message_id</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>phone_numbers</th>\n",
       "      <th>prices</th>\n",
       "      <th>tokens</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>contains_phone</th>\n",
       "      <th>contains_price</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>ethio_brand_collection</td>\n",
       "      <td>6081</td>\n",
       "      <td>2025-05-17T05:44:59+00:00</td>\n",
       "      <td>Skechers Quantum flex \\nsize 40,41,42,43\\nPric...</td>\n",
       "      <td>['0920238243']</td>\n",
       "      <td>['', '', '', '', '', '']</td>\n",
       "      <td>[Skechers, Quantum, flex, size, 40,41,42,43, P...</td>\n",
       "      <td>Skechers Quantum flex size 40,41,42,43 Price 3...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Skechers Quantum flex size 40,41,42,43 Price 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>meneshayeofficial</td>\n",
       "      <td>951</td>\n",
       "      <td>2025-03-02T11:19:30+00:00</td>\n",
       "      <td>ለበለጠ መረጃ ከታች ያለውን ማስፈንጠሪያ ይጫኑ\\n\\nhttps://menes...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ለበለጠ, መረጃ, ከታች, ያለውን, ማስፈንጠሪያ, ይጫኑ]</td>\n",
       "      <td>ለበለጠ መረጃ ከታች ያለውን ማስፈንጠሪያ ይጫኑ</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>ለበለጠ መረጃ ከታች ያለውን ማስፈንጠሪያ ይጫኑ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>ethio_brand_collection</td>\n",
       "      <td>6090</td>\n",
       "      <td>2025-05-28T09:05:44+00:00</td>\n",
       "      <td>Skechers Out door taupe \\nSize 40,41,42,43\\nPr...</td>\n",
       "      <td>['0920238243']</td>\n",
       "      <td>['', '', '', '', '', '']</td>\n",
       "      <td>[Skechers, Out, door, taupe, Size, 40,41,42,43...</td>\n",
       "      <td>Skechers Out door taupe Size 40,41,42,43 Price...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Skechers Out door taupe Size 40,41,42,43 Price...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    channel  message_id                       date  \\\n",
       "245  ethio_brand_collection        6081  2025-05-17T05:44:59+00:00   \n",
       "190       meneshayeofficial         951  2025-03-02T11:19:30+00:00   \n",
       "236  ethio_brand_collection        6090  2025-05-28T09:05:44+00:00   \n",
       "\n",
       "                                                  text   phone_numbers  \\\n",
       "245  Skechers Quantum flex \\nsize 40,41,42,43\\nPric...  ['0920238243']   \n",
       "190  ለበለጠ መረጃ ከታች ያለውን ማስፈንጠሪያ ይጫኑ\\n\\nhttps://menes...              []   \n",
       "236  Skechers Out door taupe \\nSize 40,41,42,43\\nPr...  ['0920238243']   \n",
       "\n",
       "                       prices  \\\n",
       "245  ['', '', '', '', '', '']   \n",
       "190                        []   \n",
       "236  ['', '', '', '', '', '']   \n",
       "\n",
       "                                                tokens  \\\n",
       "245  [Skechers, Quantum, flex, size, 40,41,42,43, P...   \n",
       "190               [ለበለጠ, መረጃ, ከታች, ያለውን, ማስፈንጠሪያ, ይጫኑ]   \n",
       "236  [Skechers, Out, door, taupe, Size, 40,41,42,43...   \n",
       "\n",
       "                                            clean_text  contains_phone  \\\n",
       "245  Skechers Quantum flex size 40,41,42,43 Price 3...            True   \n",
       "190                      ለበለጠ መረጃ ከታች ያለውን ማስፈንጠሪያ ይጫኑ           False   \n",
       "236  Skechers Out door taupe Size 40,41,42,43 Price...            True   \n",
       "\n",
       "     contains_price                                            content  \n",
       "245            True  Skechers Quantum flex size 40,41,42,43 Price 3...  \n",
       "190           False                      ለበለጠ መረጃ ከታች ያለውን ማስፈንጠሪያ ይጫኑ  \n",
       "236            True  Skechers Out door taupe Size 40,41,42,43 Price...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "865b9a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty prices lists: 0\n"
     ]
    }
   ],
   "source": [
    "empty_prices_count = df['prices'].apply(lambda x: isinstance(x, list) and len(x) == 0).sum()\n",
    "print(f\"Empty prices lists: {empty_prices_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43a26cb",
   "metadata": {},
   "source": [
    "# problem\n",
    "price column has no exact price what to do\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
